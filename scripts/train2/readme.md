# Training

This is the training code used for the NViSII [paper](). You can also use this training script on the training data generated by the training script in `scripts/nvisii_data_gen/`

```
python -m torch.distributed.launch --nproc_per_node=1 train.py --network dope --epochs 2 --batchsize 10 --outf tmp/ --data ../nvisii_data_gen/output/output_example/
```

There is an accompanying dataset you can also use to train DOPE on the meat can with the shiny top. [link here](https://drive.google.com/file/d/1Q5VLnlt1gu2pKIAcUo9uzSyWw1nGlSF8/view?usp=sharing).

# Inference

I also made an inference script that runs without any ROS components.

```
python inference.py
``` 

Look at the file for more information, similar to the ROS node everything is run through the yaml files in `config_inference`. It is very similar to the original code with some changes. 

Check `models.py` as we are proposing different architectures.

### (update 23/10/2023) Additional comments
Output json files include:
- The field `camera_data` which contains the camera intrinsics (cx, cy, fx, fy) lifted from `camera_info.yml`, and the **original** dimensions (width, height) of the images the inference is ran on (during inference they are downscaled)
- A list of the detected objects. For every object, the info saved is: the class name, location in camera system coordinates (in meters), rotation as a quaternion, and the coordinates of the projected cuboid (8 vertices + centroid). The projected cuboid is the result of the projection of the 3D cuboid using the camera matrix and the R,t estimated by the network. The output of the inference also includes visualizations of the projected cuboids on the images, as well as visualizations of the calculated belief maps.

**The inference algorithm in a nutshell:**
- The DOPE network calculates the belief maps for the image currently processed
- The cuboid of the object of interest is detected from the belief maps and the 2D coordinates are extracted
- The 2D cuboid coordinates along with the 3D cuboid are used with a PnP solver to calculate the object pose (R,t)
- The 3D cuboid is projected on the image using the camera matrix and R,t